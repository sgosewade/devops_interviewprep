Why docker is preferred?

Because Docker containers encapsulate everything an application needs to run (and only those things), they allow applications to be 
shuttled easily between environments. Any host with the Docker runtime installed—be it a developer's laptop or a public cloud instance—can run a Docker container.

How Are Docker Containers Created?
A Docker image is built using a Docker file. The Docker file is a text-based script, and the text file within the Docker 
file has all the commands to run the appropriate technologies within the Docker image. 

The Docker image enables you to have a broad group of people run the same environment. 
If you want to share a Docker image, uploading it to Docker Hub can easily accomplish this. 
You can access and share on Docker Hub through the public Docker Hub website, or set up your private enterprise account. 


The environment itself is highly portable 
run multiple Docker containers in a single environment,
allows you to scale your environment quickly. 
fasr boot up time
Docker ensures that applications that are running on containers are completely segregated and isolated from each other, 
granting you complete control over traffic flow and management. 
CI Efficiency.
Compatibility and Maintainability.

Docker Hub is a service provided by Docker for finding and sharing container images with your team. 
It is the world’s largest repository of container images with an array of content sources including container community developers, 
open source projects and independent software vendors (ISV) building and distributing their code in containers.

Sample docker-compose.yml file looks like:

version: "7"
services:
  testservice:
    # replace username/repo:tag with your name and image details
    image: <image name>
    deploy:
      replicas: 10
      resources:
        limits:
          cpus: "0.2"
          memory: 70M
      restart_policy:
        condition: on-failure
    ports:
      - "9080:80"
    networks:
      - webnet
This docker-compose.yml is reflected upon below:

Pull the image from Docker registry .
Run 10 instances of the pulled image as a service called testservice, with setting limits on each one as, 20% of a single core of CPU time and 70 MB of RAM.
Immediately restart containers on failure.
Map port 9080 on the host system to test services port 80.
test services containers share port 80 through a load-balanced network called webnet.

Docker Hub provides the following major features:

Repositories: Push and pull container images.
Teams & Organizations: Manage access to private repositories of container images.
Official Images: Pull and use high-quality container images provided by Docker.
Publisher Images: Pull and use high- quality container images provided by external vendors.
Builds: Automatically build container images from GitHub and Bitbucket and push them to Docker Hub.
Webhooks: Trigger actions after a successful push to a repository to integrate Docker Hub with other services.

Benefits of Docker Compose
Single host deployment - This means you can run everything on a single piece of hardware
Quick and easy configuration - Due to YAML scripts
High productivity - Docker Compose reduces the time it takes to perform tasks
Security - All the containers are isolated from each other, reducing the threat landscape

docker

Basic Commands in Docker Compose
Start all services: Docker Compose up
Stop all services: Docker Compose down
Install Docker Compose using pip: pip install -U Docker-compose
Check the version of Docker Compose: Docker-compose-v
Run Docker Compose file: Docker-compose up -d
List the entire process: Docker ps
Scale a service - Docker Compose up -d -scale
Use YAML files to configure application services - Docker Compose.yml



Cloud load balancing is defined as the method of splitting workloads and computing properties in a cloud computing. 
It enables enterprise to manage workload demands or application demands by 
distributing resources among numerous computers, networks or servers. 
Cloud load balancing includes holding the circulation of workload traffic and demands that exist over the Internet.

Sample Dockerfile :

FROM ubuntu:16.04
COPY . /app
RUN make /app
CMD python /app/app.py

Following commands could be used to manage volumes:

docker volume create <name> to create the volume
docker volume ls to list the volumes available to you
docker volume inspect <name> to get more details about the volume like path, drivers etc.
docker volume rm <name> to remove the container.
docker volume prune to remove unused volumes

FROM instruction    
Usage :

FROM <image> [AS <name>]
Or

FROM <image>[:<tag>] [AS <name>]
Or

FROM <image>[@<digest>] [AS <name>]
FROM helps to set the base image for the following instructions in the Dockerfile. The base image could be one pulled from the remote public repository or a local image built by the user. FROM can appear multiple times in Dockerfile and each time it appears it clears any stage created from previous instructions. Hence usually an AS <NAME> is added to the FROM instruction to identify the last image created just before the FROM instruction.  

RUN instruction
Usage:

RUN <command> (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows)
RUN ["executable", "param1", "param2"] (exec form)
RUN instruction creates a new layer on the current image which is used for the next step in Dockerfile.
RUN cache is valid for the next build provided “docker build” command is not run with “--no-cache” flag.

RUN in the executable form doesn’t do shell processing like variable substitution.

CMD instruction
Usage:

CMD ["executable","param1","param2"] (exec form, this is the preferred form)
CMD ["param1","param2"] (as default parameters to ENTRYPOINT)
CMD command param1 param2 (shell form)
CMD provides defaults for executing container. 
There could only be one CMD instruction but if there are many, only the last one has the effect. 
If CMD is providing default arguments for the ENTRYPOINT instruction, then the CMD and ENTRYPOINT instructions should be specified with the JSON array format.  

ADD instruction
Usage:

ADD [--chown=<user>:<group>] <src>... <dest>
ADD [--chown=<user>:<group>] ["<src>",... "<dest>"] (this form is required for paths containing whitespace)
The ADD instruction copies new files, directories or remote file URLs from <src> and adds them to the filesystem of the image at the path <dest>.

COPY instruction
Usage:

COPY [--chown=<user>:<group>] <src>... <dest>
COPY [--chown=<user>:<group>] ["<src>",... "<dest>"] (this form is required for paths containing whitespace)
The COPY instruction copies new files or directories from <src> and adds them to the filesystem of the container at the path <dest>.Main difference between COPY and ADD is that ADD supports the source to be a URL or tar file.

ENTRYPOINT
Usage:

ENTRYPOINT ["executable", "param1", "param2"] (exec form, preferred)
ENTRYPOINT command param1 param2 (shell form)
An ENTRYPOINT allows you to configure a container that will run as an executable. 
As a best practice ENTRYPOINT should be defined when using the container as an executable and 
CMD should be used as a way of defining default arguments for an ENTRYPOINT command.
CMD could be overridden while running a container with arguments.

WORKDIR
Usage:

WORKDIR /path/to/workdir
The WORKDIR instruction sets the working directory for RUN, CMD, ENTRYPOINT, COPY and ADD instructions in the Dockerfile.
